{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipykernel==6.29.4\n",
    "%pip install python-dotenv==1.0.1\n",
    "%pip install simclr==1.0.2\n",
    "%pip install roboflow==1.1.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "\n",
    "from roboflow import Roboflow\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "rf = Roboflow(api_key=os.getenv(\"ROBOFLOW_API_KEY\"))\n",
    "project = rf.workspace(\"yaid-pzikt\").project(\"firefighting-device-detection\")\n",
    "version = project.version(6)\n",
    "dataset = version.download(\"yolov8\")\n",
    "dataset.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "data_dir = './Firefighting-Device-Detection-6'\n",
    "imagenet_int_to_str = {}\n",
    "\n",
    "with open(os.path.join(data_dir, 'data.yaml'), 'r') as f:\n",
    "  data = yaml.safe_load(f)\n",
    "\n",
    "labels = data.get('names', [])\n",
    "num_classes = data.get('nc', [])\n",
    "assert len(labels) == num_classes\n",
    "labels, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model\n",
    "\n",
    "model_path = \"checkpoint_100.tar\"\n",
    "!wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/$model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config: https://github.com/Spijkervet/SimCLR/blob/master/config/config.yaml\n",
    "\n",
    "config = {\n",
    "    \"image_size\": 224,\n",
    "    \"workers\": 8,\n",
    "    \"resnet\": \"resnet50\",\n",
    "    \"projection_dim\": 64,\n",
    "    \"max_boxes\": 50,\n",
    "    \"trials\": 5,\n",
    "    \"epochs\": 15,\n",
    "    \"batch_size\": [2, 8], # range to sample from\n",
    "    \"lr\": [1e-7, 1e-4],\n",
    "    \"weight_decay\": [1e-6, 1e-4],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed SimCLR transforms: https://github.com/Spijkervet/SimCLR/blob/master/simclr/modules/transformations/simclr.py\n",
    "\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class TransformsSimCLR:\n",
    "    \"\"\"\n",
    "    A stochastic data augmentation module that transforms any given data example randomly\n",
    "    resulting in two correlated views of the same example,\n",
    "    denoted x ̃i and x ̃j, which we consider as a positive pair.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        s = 1\n",
    "        color_jitter = torchvision.transforms.ColorJitter(\n",
    "            0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s\n",
    "        )\n",
    "        self.train_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.RandomResizedCrop(size=size),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),  # with 0.5 probability\n",
    "                torchvision.transforms.RandomApply([color_jitter], p=0.8),\n",
    "                torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.test_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize(size=(size, size)),  # Single int didn't work\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.train_transform(x), self.train_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class DetectionDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        path = os.path.join(data_dir, split)\n",
    "        images_dir = os.path.join(path, \"images\")\n",
    "        labels_dir = os.path.join(path, \"labels\")\n",
    "        self.image_paths = glob.glob(os.path.join(images_dir, \"*.jpg\"))\n",
    "        self.label_paths = glob.glob(os.path.join(labels_dir, \"*.txt\"))\n",
    "\n",
    "        transform = TransformsSimCLR(size=config[\"image_size\"])\n",
    "        if split == \"train\":\n",
    "            self.apply_transform = transform.train_transform\n",
    "        else:\n",
    "            self.apply_transform = transform.test_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label_path = self.label_paths[idx]\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.apply_transform(image)\n",
    "\n",
    "        annotations = []\n",
    "        with open(label_path, 'r') as file:\n",
    "            for line in file:\n",
    "                class_id, x_min, y_min, x_max, y_max = map(float, line.strip().split())\n",
    "                annotations.append((int(class_id), x_min, y_min, x_max, y_max))\n",
    "\n",
    "        # Pad if necessary\n",
    "        if len(annotations) > config[\"max_boxes\"]:\n",
    "            annotations = annotations[:config[\"max_boxes\"]]\n",
    "        elif len(annotations) < config[\"max_boxes\"]:\n",
    "            annotations += [(0, 0, 0, 0, 0)] * (config[\"max_boxes\"] - len(annotations))\n",
    "\n",
    "        class_ids = torch.tensor([a[0] for a in annotations], dtype=torch.long)\n",
    "        boxes = torch.tensor([a[1:] for a in annotations], dtype=torch.float32)\n",
    "        \n",
    "        return image, class_ids, boxes\n",
    "    \n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, class_ids, boxes = zip(*batch)\n",
    "    images = torch.stack(images)\n",
    "    class_ids = torch.stack(class_ids)\n",
    "    boxes = torch.stack(boxes)\n",
    "    return images, (class_ids, boxes)\n",
    "\n",
    "\n",
    "train_dataset = DetectionDataset(split=\"train\")\n",
    "valid_dataset = DetectionDataset(split=\"valid\")\n",
    "test_dataset = DetectionDataset(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object detection model\n",
    "\n",
    "import torch.nn as nn\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import get_resnet\n",
    "\n",
    "\n",
    "class DetectionModel(nn.Module):\n",
    "    def __init__(self, simclr_model):\n",
    "        super(DetectionModel, self).__init__()\n",
    "        self.feature_extractor = simclr_model.encoder\n",
    "        self.bbox_regressor = nn.Linear(simclr_model.n_features, config[\"max_boxes\"] * 4)\n",
    "        self.classifier = nn.Linear(simclr_model.n_features, config[\"max_boxes\"] * (num_classes + 1))  # +1 for background\n",
    "\n",
    "    def forward(self, img):\n",
    "        features = self.feature_extractor(img)\n",
    "        class_logits = self.classifier(features).view(-1, config[\"max_boxes\"], num_classes + 1)\n",
    "        bboxes = self.bbox_regressor(features).view(-1, config[\"max_boxes\"], 4)\n",
    "        return class_logits, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "\n",
    "def detection_loss(pred_classes, pred_boxes, true_labels, true_boxes):    \n",
    "    flat_pred_classes = pred_classes.view(-1, pred_classes.size(-1))  # Flatten to [batch_size * max_boxes, num_classes]\n",
    "    flat_true_labels = true_labels.view(-1)  # Flatten to [batch_size * max_boxes]\n",
    "    \n",
    "    valid_mask = true_labels > 0\n",
    "\n",
    "    valid_indices = valid_mask.view(-1)\n",
    "    class_loss = nn.CrossEntropyLoss()(flat_pred_classes[valid_indices], flat_true_labels[valid_indices])\n",
    "    \n",
    "    valid_boxes = valid_mask.unsqueeze(-1).expand_as(true_boxes) \n",
    "    loc_loss = nn.SmoothL1Loss()(pred_boxes[valid_boxes], true_boxes[valid_boxes])\n",
    "\n",
    "    return class_loss + loc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "\n",
    "def validate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for images, (class_labels, bbox) in dataloader:\n",
    "        images = images.to(device)\n",
    "        class_labels = class_labels.to(device)\n",
    "        bbox = bbox.to(device)\n",
    "        with torch.no_grad():\n",
    "            predicted_classes, predicted_bboxes = model(images)\n",
    "            loss = detection_loss(predicted_classes, predicted_bboxes, class_labels, bbox )\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = get_resnet(config[\"resnet\"], pretrained=False)\n",
    "n_features = encoder.fc.in_features\n",
    "\n",
    "# load pre-trained model from checkpoint\n",
    "simclr_model = SimCLR(encoder=encoder, projection_dim=config[\"projection_dim\"], n_features=n_features)\n",
    "simclr_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "simclr_model = simclr_model.to(device)\n",
    "\n",
    "model = DetectionModel(simclr_model)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "for trial in range(config[\"trials\"]):\n",
    "    bs = random.randint(config[\"batch_size\"][0], config[\"batch_size\"][1])\n",
    "    lr = 10 ** random.uniform(math.log10(config[\"lr\"][0]), math.log10(config[\"lr\"][1]))\n",
    "    wd = 10 ** random.uniform(math.log10(config[\"weight_decay\"][0]), math.log10(config[\"weight_decay\"][1]))\n",
    "    \n",
    "    print(f\"Trial {trial + 1}/{config['trials']}\")\n",
    "    print(f\"Batch size: {bs}, Learning rate: {lr}, Weight decay: {wd}\")\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True, drop_last=True, num_workers=config[\"workers\"], collate_fn=collate_fn)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=bs, shuffle=False, drop_last=True, num_workers=config[\"workers\"], collate_fn=collate_fn)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=True, num_workers=config[\"workers\"], collate_fn=collate_fn)\n",
    "\n",
    "    # Setup optimizers and loss for the detection task\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    criterion = {\n",
    "        'bbox': nn.SmoothL1Loss(),\n",
    "        'class': nn.CrossEntropyLoss()\n",
    "    }\n",
    "\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        train_loss = 0\n",
    "        for images, (class_labels, bbox) in train_dataloader:\n",
    "            images = images.to(device)\n",
    "            class_labels = class_labels.to(device)\n",
    "            bbox = bbox.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predicted_classes, predicted_bboxes = model(images)\n",
    "            loss = detection_loss(predicted_classes, predicted_bboxes, class_labels, bbox)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss / len(train_dataloader)}')\n",
    "        \n",
    "        val_loss = validate_model(model, valid_dataloader, device)\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Validation Loss: {val_loss}')\n",
    "    \n",
    "    # Test model\n",
    "    test_loss = validate_model(model, test_dataloader, device)\n",
    "    print(f'Test Loss: {test_loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bobyard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
